{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('SMSSpamCollection.txt', header=None)\n",
    "df.columns = ['y', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df.iloc[:, 0].map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df.text\n",
    "labels = df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_classifier(vectorizer, transformer, classifier):\n",
    "    return Pipeline(\n",
    "            [(\"vectorizer\", vectorizer),\n",
    "            (\"transformer\", transformer),\n",
    "            (\"classifier\", classifier)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "0.9311542822856882\n",
      "\n",
      "\n",
      "<class 'sklearn.svm._classes.LinearSVC'>\n",
      "0.9412219459766616\n",
      "\n",
      "\n",
      "<class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\n",
      "0.9282294081136653\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in [LogisticRegression, LinearSVC, SGDClassifier]:\n",
    "    print(clf)\n",
    "    print(cross_val_score(Pipeline([(\"vectorizer\", CountVectorizer()), \n",
    "                                    (\"classifier\", clf(max_iter=1000))]),\n",
    "                          texts, labels, cv=10, scoring='f1').mean())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([(\"vectorizer\", CountVectorizer()),\n",
    "                (\"transformer\", TfidfTransformer()),\n",
    "                (\"classifier\", LogisticRegression(max_iter=1000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabula...\n",
       "                ('transformer',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=1000,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\",\n",
    "        \"FreeMsg: Txt: claim your reward of 3 hours talk time\",\n",
    "        \"Have you visited the last lecture on physics?\",\n",
    "        \"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\",\n",
    "        \"Only 99$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)  : 0.817\n",
      "(3, 3)  : 0.725\n",
      "(1, 3)  : 0.922\n"
     ]
    }
   ],
   "source": [
    "for ngram in [(2,2), (3,3), (1,3)]:\n",
    "    clf = Pipeline([(\"vectorizer\", CountVectorizer(ngram_range=ngram)),\n",
    "                    #(\"transformer\", TfidfTransformer()),\n",
    "                    (\"classifier\", LogisticRegression(max_iter=1000))])\n",
    "    '''clf = text_classifier(CountVectorizer(ngram_range=ngram), TfidfTransformer(), LogisticRegression(max_iter=1000))'''\n",
    "    score = cross_val_score(clf, texts, labels, cv=10, scoring='f1').mean()\n",
    "    print(f'{ngram}  : {score:.3f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas 0.25.3\n",
      "Numpy 1.17.4\n",
      "Scikit-Learn 0.22.1\n",
      "NLTK 3.4.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import nltk\n",
    "\n",
    "print(f'Pandas {pd.__version__}')\n",
    "print(f'Numpy {np.__version__}')\n",
    "print(f'Scikit-Learn {sklearn.__version__}')\n",
    "print(f'NLTK {nltk.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)  : 0.646\n",
      "(3, 3)  : 0.379\n",
      "(1, 3)  : 0.888\n"
     ]
    }
   ],
   "source": [
    "for ngram in [(2,2), (3,3), (1,3)]:\n",
    "    X = CountVectorizer(ngram_range=ngram).fit_transform(texts)\n",
    "    score = cross_val_score(MultinomialNB(), X, labels, cv=10, scoring='f1').mean()\n",
    "    print(f'{ngram}  : {score:.3f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)  : 0.829\n",
      "(2, 2)  : 0.776\n",
      "(3, 3)  : 0.665\n",
      "(1, 3)  : 0.742\n"
     ]
    }
   ],
   "source": [
    "for ngram in [(1,1), (2,2), (3,3), (1,3)]:\n",
    "    clf = Pipeline([(\"vectorizer\", TfidfVectorizer(ngram_range=ngram)),\n",
    "                    #(\"transformer\", TfidfTransformer()),\n",
    "                    (\"classifier\", MultinomialNB())])\n",
    "    '''clf = text_classifier(CountVectorizer(ngram_range=ngram), TfidfTransformer(), Log\"classifier\",isticRegression(max_iter=1000))'''\n",
    "    score = cross_val_score(clf, texts, labels, cv=10, scoring='f1').mean()\n",
    "    print(f'{ngram}  : {score:.3f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.2'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
